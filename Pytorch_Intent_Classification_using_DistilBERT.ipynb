{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Intent Classification using DistilBERT",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajesh-bhat/data-aisummit-2021-databricks-conversational-ai/blob/main/Pytorch_Intent_Classification_using_DistilBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEDAh-hQv_NW"
      },
      "source": [
        "### Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQN0gM1NwBOv",
        "outputId": "d87c465c-c420-469a-a5ad-bbe9cd0f77de"
      },
      "source": [
        "!pip install pandas torch transformers tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWAbRfCDxLjK"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1f7w6TmxNor",
        "outputId": "50ac3be0-e0fa-4428-d25a-4ad5eedb1541"
      },
      "source": [
        "!gdown --id 1OlcvGWReJMuyYQuOZm149vHWwPtlboR6 --output train.csv\n",
        "!gdown --id 1Oi5cRlTybuIF2Fl5Bfsr-KkqrXrdt77w --output valid.csv\n",
        "!gdown --id 1ep9H6-HvhB4utJRLVcLzieWNUSG3P_uF --output test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OlcvGWReJMuyYQuOZm149vHWwPtlboR6\n",
            "To: /content/train.csv\n",
            "100% 799k/799k [00:00<00:00, 12.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Oi5cRlTybuIF2Fl5Bfsr-KkqrXrdt77w\n",
            "To: /content/valid.csv\n",
            "100% 43.3k/43.3k [00:00<00:00, 67.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ep9H6-HvhB4utJRLVcLzieWNUSG3P_uF\n",
            "To: /content/test.csv\n",
            "100% 43.1k/43.1k [00:00<00:00, 6.35MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Ye3UrCxTrw"
      },
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3aQV2_NNxVP4",
        "outputId": "ff7e3102-29a6-429c-8832-02a7eb2a25ad"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.concat([pd.read_csv(file) for file in [\"train.csv\",\"valid.csv\"]])\n",
        "train = train.groupby('intent').sample(frac=0.25)\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3447, 2)\n",
            "(700, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3046</th>\n",
              "      <td>add artist to my trance life group</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11842</th>\n",
              "      <td>i want to put this song in my new boots playlist</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11804</th>\n",
              "      <td>add suffer little children to this is racionai...</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11486</th>\n",
              "      <td>add vikku vinayakram to my this is nicky jam</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5078</th>\n",
              "      <td>incorporate a roberto parra sandoval track int...</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text         intent\n",
              "3046                  add artist to my trance life group  AddToPlaylist\n",
              "11842   i want to put this song in my new boots playlist  AddToPlaylist\n",
              "11804  add suffer little children to this is racionai...  AddToPlaylist\n",
              "11486       add vikku vinayakram to my this is nicky jam  AddToPlaylist\n",
              "5078   incorporate a roberto parra sandoval track int...  AddToPlaylist"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwZJ0H8Oxr7R",
        "outputId": "882c3177-e683-406b-a53e-f3d09deedfcc"
      },
      "source": [
        "train.intent.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PlayMusic               504\n",
              "GetWeather              499\n",
              "BookRestaurant          495\n",
              "RateBook                494\n",
              "SearchScreeningEvent    488\n",
              "SearchCreativeWork      487\n",
              "AddToPlaylist           480\n",
              "Name: intent, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Wu6IQDFWzrbR",
        "outputId": "87764af5-c330-4b97-8be5-a429599b372f"
      },
      "source": [
        "intent_mapping = {x:idx for idx,x in enumerate(train.intent.unique().tolist())}\n",
        "train['target'] = train['intent'].map(intent_mapping)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3046</th>\n",
              "      <td>add artist to my trance life group</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11842</th>\n",
              "      <td>i want to put this song in my new boots playlist</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11804</th>\n",
              "      <td>add suffer little children to this is racionai...</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11486</th>\n",
              "      <td>add vikku vinayakram to my this is nicky jam</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5078</th>\n",
              "      <td>incorporate a roberto parra sandoval track int...</td>\n",
              "      <td>AddToPlaylist</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text         intent  target\n",
              "3046                  add artist to my trance life group  AddToPlaylist       0\n",
              "11842   i want to put this song in my new boots playlist  AddToPlaylist       0\n",
              "11804  add suffer little children to this is racionai...  AddToPlaylist       0\n",
              "11486       add vikku vinayakram to my this is nicky jam  AddToPlaylist       0\n",
              "5078   incorporate a roberto parra sandoval track int...  AddToPlaylist       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDmITX3PwZhY"
      },
      "source": [
        "### Load libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAFg1c7XwUlt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKBltmzmwPzf"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, AdamW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZY-mKjgE8Cd"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H72KVArzwXBt"
      },
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"To make the training process reproducible\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, queries, intents, tokenizer, max_len):\n",
        "        self.queries = queries\n",
        "        self.intents = intents\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.queries)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        query = self.queries[index]\n",
        "        intent = self.intents[index]\n",
        "\n",
        "        # use encode plus of huggingface tokenizer to encode the sentence.\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            query,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"intent\": torch.tensor(intent, dtype=torch.long),\n",
        "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
        "        }\n",
        "    \n",
        "\n",
        "def dataset_loader(queries, intents, tokenizer, max_len, batch_size):\n",
        "    ds = MyDataset(\n",
        "        queries=queries.to_numpy(),\n",
        "        intents=intents.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len,\n",
        "    )\n",
        "\n",
        "    return DataLoader(ds, batch_size=batch_size, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9GPIYfpE5ki"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkNzUDy0yTH7",
        "outputId": "78b4c65e-881e-42a3-84d0-e369ec58a1dd"
      },
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "MAX_LEN = 256\n",
        "EPOCHS = 3\n",
        "SEED = 42\n",
        "\n",
        "set_seed(SEED)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "train_dataloader = dataset_loader(queries=train['text'], \n",
        "                                  intents=train['target'], \n",
        "                                  tokenizer=tokenizer,\n",
        "                                  max_len=MAX_LEN,\n",
        "                                  batch_size=BATCH_SIZE)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=7)\n",
        "model.to(DEVICE)\n",
        "model.train()\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        targets = batch['intent'].to(DEVICE)\n",
        "        outputs = model(input_ids=input_ids, \n",
        "                        attention_mask=attention_mask, \n",
        "                        labels=targets)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Training loss in epoch {epoch+1}: {round(loss.item(),4)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 54/54 [01:15<00:00,  1.39s/it]\n",
            "  0%|          | 0/54 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss in epoch 1: 1.1031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54/54 [01:14<00:00,  1.38s/it]\n",
            "  0%|          | 0/54 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss in epoch 2: 0.596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54/54 [01:14<00:00,  1.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss in epoch 3: 0.512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlhkE4EnE_Zg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1ih_TkypIa"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    if tensor.requires_grad:\n",
        "        return tensor.detach().cpu().numpy()\n",
        "    return tensor.cpu().numpy()\n",
        "\n",
        "\n",
        "def score(model, tokenizer, intent_mapping, query):\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        query,\n",
        "        add_special_tokens=True,\n",
        "        max_length=MAX_LEN,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_token_type_ids=False,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "    output = model(input_ids, attention_mask)\n",
        "    probs = F.softmax(output.logits, dim=1)\n",
        "    _, prediction = torch.max(output.logits, dim=1)\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"predicted_intent\": intent_mapping.get(prediction[0].item())\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50g-njXSET4J",
        "outputId": "8ef9f174-823a-4b34-dff2-03329a09b7cf"
      },
      "source": [
        "query = test['text'][3]\n",
        "score(model=model.to('cpu'), \n",
        "      tokenizer=tokenizer, \n",
        "      intent_mapping={value: key for key, value in intent_mapping.items()}, \n",
        "      query=query)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'predicted_intent': 'SearchScreeningEvent',\n",
              " 'query': 'will it snow in mt on june 13  2038'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gygp6fGCIpvs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}